{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/prasaddash/prasad-brats-d1?scriptVersionId=92048628\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"import nibabel as nib\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport os\nimport random\nimport torch\nimport pandas as pd\nfrom tqdm.notebook import tqdm_notebook\nfrom torchvision import transforms, utils\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2022-04-04T06:00:27.065547Z","iopub.execute_input":"2022-04-04T06:00:27.066391Z","iopub.status.idle":"2022-04-04T06:00:29.329035Z","shell.execute_reply.started":"2022-04-04T06:00:27.066274Z","shell.execute_reply":"2022-04-04T06:00:29.32826Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import tarfile\nfile = tarfile.open('../input/brats-2021-task1/BraTS2021_Training_Data.tar')\n\nfile.extractall('./brain_images')\nfile.close()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T06:00:29.330352Z","iopub.execute_input":"2022-04-04T06:00:29.33127Z","iopub.status.idle":"2022-04-04T06:02:54.284067Z","shell.execute_reply.started":"2022-04-04T06:00:29.331218Z","shell.execute_reply":"2022-04-04T06:02:54.282955Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"PATIENT_ID='00558'\nT1_PATH=f\"./brain_images/BraTS2021_{PATIENT_ID}/BraTS2021_{PATIENT_ID}_t1.nii.gz\"\nT1CE_PATH=f\"./brain_images/BraTS2021_{PATIENT_ID}/BraTS2021_{PATIENT_ID}_t1ce.nii.gz\"\nT2_PATH=f\"./brain_images/BraTS2021_{PATIENT_ID}/BraTS2021_{PATIENT_ID}_t2.nii.gz\"\nFLAIR_PATH=f\"./brain_images/BraTS2021_{PATIENT_ID}/BraTS2021_{PATIENT_ID}_flair.nii.gz\"\nMASK_PATH=f\"./brain_images/BraTS2021_{PATIENT_ID}/BraTS2021_{PATIENT_ID}_seg.nii.gz\"\nimg_t1=nib.load(T1_PATH)\nimg_t1ce=nib.load(T1CE_PATH)\nimg_t2=nib.load(T2_PATH)\nimg_flair=nib.load(FLAIR_PATH)\nimg_mask=nib.load(MASK_PATH)\nimage_data_t1=img_t1.get_fdata()\nimage_data_t1ce=img_t1ce.get_fdata()\nimage_data_t2=img_t2.get_fdata()\nimage_data_flair=img_flair.get_fdata()\nmask=img_mask.get_fdata()\nprint(img_t1.header)\nzero_matrix=np.zeros((240,240))\nstart=-1\nend=1e9\nnonEmptyMasks=[]\nfor i in range(0,155):\n    if not np.array_equal(zero_matrix,mask[:,:,i]):\n        if start==-1:\n                start=i\n        nonEmptyMasks.append(i)\n        if i<end:\n            end=i\n\ndef one_normal(x):\n    if x==0:\n        return 0\n    else:\n        return 1\nprint(image_data_t1.min())\nplt.rcParams.update({'text.color': \"red\"})\nLAYER=random.choice(nonEmptyMasks)\nLAYER=93\nfig = plt.figure(figsize=(100,50))\nrows = 5\ncols=1\nfig.add_subplot(rows, cols, 1)\ncmask=np.vectorize(one_normal)(mask[:,:,LAYER])\nplt.imshow(image_data_t1[:,:,LAYER]*cmask,cmap='gray')\nplt.axis('off')\nplt.title(\"T1\")\nfig.add_subplot(rows, cols,2)\nplt.imshow(image_data_t1ce[:,:,LAYER]*cmask,cmap='gray')\nplt.axis('off')\nplt.title(\"T1CE\")\nfig.add_subplot(rows, cols, 3)\nplt.imshow(image_data_t2[:,:,LAYER]*cmask,cmap='gray')\nplt.axis('off')\nplt.title(\"T2\")\nfig.add_subplot(rows, cols, 4)\nplt.imshow(image_data_flair[:,:,LAYER]*cmask,cmap='gray')\nplt.axis('off')\nplt.title(\"FLAIR\")\nfig.add_subplot(rows, cols, 5)\nplt.imshow(mask[:,:,LAYER],cmap='gray')\nplt.axis('off')\nplt.title(\"MASK\")\nfig.suptitle(f'Layer Number {LAYER}', fontsize=20)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-03T19:31:07.452558Z","iopub.execute_input":"2022-04-03T19:31:07.452837Z","iopub.status.idle":"2022-04-03T19:31:10.125872Z","shell.execute_reply.started":"2022-04-03T19:31:07.452802Z","shell.execute_reply":"2022-04-03T19:31:10.125207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_T1=-1\nMIN_T1=1e9\nfor i in tqdm_notebook(ALL_MGMT_PATIENTS,desc='T1'):\n    img_t1=nib.load(f\"./brain_images/BraTS2021_{i}/BraTS2021_{i}_t1.nii.gz\")\n    image_data=img_t1.get_fdata()\n    MAX_T1=max(MAX_T1,image_data.max())\n    print(i,image_data.min())\n    MIN_T1=min(MIN_T1,image_data.min())\nprint(\"Max Intensity in T1 Images : \",MAX_T1)\nprint(\"Min Intensity in T1 Images : \",MIN_T1)\nMAX_T1CE=-1\nMIN_T1CE=1e9\nfor i in tqdm_notebook(ALL_MGMT_PATIENTS,desc='T1CE'):\n    img_t1=nib.load(f\"./brain_images/BraTS2021_{i}/BraTS2021_{i}_t1ce.nii.gz\")\n    image_data=img_t1.get_fdata()\n    MAX_T1CE=max(MAX_T1CE,image_data.max())\n    MIN_T1CE=min(MIN_T1CE,image_data.min())\nprint(\"Max Intensity in T1 Images : \",MAX_T1CE)\nprint(\"Min Intensity in T1 Images : \",MIN_T1CE)\nMAX_T2=-1\nMIN_T2=1e9\nfor i in tqdm_notebook(ALL_MGMT_PATIENTS,desc='T2'):\n    img_t1=nib.load(f\"./brain_images/BraTS2021_{i}/BraTS2021_{i}_t2.nii.gz\")\n    image_data=img_t1.get_fdata()\n    MAX_T2=max(MAX_T2,image_data.max())\n    MIN_T2=min(MIN_T2,image_data.min())\nprint(\"Max Intensity in T2 Images : \",MAX_T2)\nprint(\"Min Intensity in T2 Images : \",MIN_T2)\nMAX_FLAIR=-1\nMIN_FLAIR=1e9\nfor i in tqdm_notebook(ALL_MGMT_PATIENTS,desc='FLAIR'):\n    img_t1=nib.load(f\"./brain_images/BraTS2021_{i}/BraTS2021_{i}_flair.nii.gz\")\n    image_data=img_t1.get_fdata()\n    MAX_FLAIR=max(MAX_FLAIR,image_data.max())\n    MIN_FLAIR=min(MIN_FLAIR,image_data.min())\nprint(\"Max Intensity in FLAIR Images : \",MAX_FLAIR)\nprint(\"Min Intensity in FLAIR Images : \",MIN_FLAIR)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T04:46:46.53645Z","iopub.execute_input":"2022-04-04T04:46:46.537375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels=pd.read_csv('../input/mgmt-labels/train_labels_MGMT.csv')\nCURRENT_FOLDER='./brain_images'\nALL_PATIENTS=[]\nfor f in tqdm_notebook(os.listdir(CURRENT_FOLDER),desc='Progress'):\n    path_to_dir=os.path.join(CURRENT_FOLDER,f)\n    if os.path.isdir(path_to_dir):\n        ALL_PATIENTS.append(f)\nALL_MGMT_PATIENTS=[str(label).zfill(5) for label in labels['BraTS21ID']]\nprint(\"Total Number of patients : \",len(ALL_PATIENTS))\nprint(\"Total Number of patients with MGMT Data : \",len(ALL_MGMT_PATIENTS))\nprint(\"Total Number of patients with MGMT Methylation Positive : \",len(labels[labels['MGMT_value']==1]))\nprint(\"Total Number of patients with MGMT Methylation Negative : \",len(labels[labels['MGMT_value']==0]))\nfor i in ALL_MGMT_PATIENTS:\n    if f'BraTS2021_{i}' not in ALL_PATIENTS:\n        print(i)\nALL_MGMT_PATIENTS=[i for i in ALL_MGMT_PATIENTS if f'BraTS2021_{i}' in ALL_PATIENTS]","metadata":{"execution":{"iopub.status.busy":"2022-04-04T06:02:54.286025Z","iopub.execute_input":"2022-04-04T06:02:54.287391Z","iopub.status.idle":"2022-04-04T06:02:54.435049Z","shell.execute_reply.started":"2022-04-04T06:02:54.287336Z","shell.execute_reply":"2022-04-04T06:02:54.432324Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Progress:   0%|          | 0/1252 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0079cf0c4054a70a544acd224f8aacd"}},"metadata":{}},{"name":"stdout","text":"Total Number of patients :  1251\nTotal Number of patients with MGMT Data :  585\nTotal Number of patients with MGMT Methylation Positive :  307\nTotal Number of patients with MGMT Methylation Negative :  278\n00169\n00197\n00245\n00308\n00408\n00564\n00794\n00998\n","output_type":"stream"}]},{"cell_type":"code","source":"NEGATIVE_IMAGES=0\nPOSITIVE_IMAGES=0\nALL_DATA=[]\nfor i in tqdm_notebook(ALL_MGMT_PATIENTS,desc='Progress'):\n    zero_matrix=np.zeros((240,240))\n    start=-1\n    end=1e9\n    nonEmptyMasks=[]\n    MASK_PATH=f\"./brain_images/BraTS2021_{i}/BraTS2021_{i}_seg.nii.gz\"\n    img_mask=nib.load(MASK_PATH)\n    mask=img_mask.get_fdata()\n    for j in range(0,155):\n        if (mask[:,:,j]>0).astype('float64').sum()>300 :\n            ALL_DATA.append((i,j,labels[labels['BraTS21ID']==int(i)]['MGMT_value'].values[0]))\n            if(labels[labels['BraTS21ID']==int(i)]['MGMT_value'].values[0]):\n                POSITIVE_IMAGES+=1\n            else:\n                NEGATIVE_IMAGES+=1","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-04T06:02:54.437315Z","iopub.execute_input":"2022-04-04T06:02:54.437562Z","iopub.status.idle":"2022-04-04T06:04:15.378728Z","shell.execute_reply.started":"2022-04-04T06:02:54.437533Z","shell.execute_reply":"2022-04-04T06:04:15.377805Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Progress:   0%|          | 0/577 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"267a464d684f46d1a35259b6d85f4550"}},"metadata":{}}]},{"cell_type":"code","source":"print(\"Final No. of Images in the dataset:\",len(ALL_DATA))\nprint(\"No of Images labelled true\",POSITIVE_IMAGES)\nprint(\"No of Images labelled false\",NEGATIVE_IMAGES)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T06:04:15.380291Z","iopub.execute_input":"2022-04-04T06:04:15.380684Z","iopub.status.idle":"2022-04-04T06:04:15.388683Z","shell.execute_reply.started":"2022-04-04T06:04:15.380635Z","shell.execute_reply":"2022-04-04T06:04:15.387974Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Final No. of Images in the dataset: 30976\nNo of Images labelled true 16387\nNo of Images labelled false 14589\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\ndataset=pd.DataFrame(ALL_DATA,columns=['id','slice','label'])","metadata":{"execution":{"iopub.status.busy":"2022-04-04T06:04:15.390287Z","iopub.execute_input":"2022-04-04T06:04:15.390539Z","iopub.status.idle":"2022-04-04T06:04:15.44145Z","shell.execute_reply.started":"2022-04-04T06:04:15.390508Z","shell.execute_reply":"2022-04-04T06:04:15.440707Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"dataset.tail()","metadata":{"execution":{"iopub.status.busy":"2022-04-03T19:32:30.512017Z","iopub.execute_input":"2022-04-03T19:32:30.512413Z","iopub.status.idle":"2022-04-03T19:32:30.527623Z","shell.execute_reply.started":"2022-04-03T19:32:30.512369Z","shell.execute_reply":"2022-04-03T19:32:30.526889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ExtractRegion(img):\n    img_x,img_y=img.shape\n    for i in range(img_x):\n        if img[i,:].sum()>0:\n            ul=i\n            break\n    for i in range(img_x-1,0,-1):\n        if img[i,:].sum()>0:\n            dl=i\n            break\n    for i in range(img_y):\n        if img[:,i].sum()>0:\n            ll=i\n            break\n    for i in range(img_y-1,0,-1):\n        if img[:,i].sum()>0:\n            rl=i\n            break\n    img = img[ul:dl+1,ll:rl+1]\n    img =  cv2.resize(img, (240,240), interpolation = cv2.INTER_CUBIC)\n    img = cv2.cvtColor(img.astype('float32'),cv2.COLOR_GRAY2RGB)\n    return img","metadata":{"execution":{"iopub.status.busy":"2022-04-04T06:04:15.442736Z","iopub.execute_input":"2022-04-04T06:04:15.443426Z","iopub.status.idle":"2022-04-04T06:04:15.452471Z","shell.execute_reply.started":"2022-04-04T06:04:15.443386Z","shell.execute_reply":"2022-04-04T06:04:15.451357Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from sklearn import tree\nfrom sklearn.metrics import classification_report\ndef predict(test,model):\n    labels = []\n    X=[]\n    for i in tqdm_notebook(range(int(len(test)))):\n        img = nib.load(f\"./brain_images/BraTS2021_{dataset['id'].loc[i]}/BraTS2021_{dataset['id'].loc[i]}_t1.nii.gz\").get_fdata()\n        mask = nib.load(f\"./brain_images/BraTS2021_{dataset['id'].loc[i]}/BraTS2021_{dataset['id'].loc[i]}_seg.nii.gz\").get_fdata()\n        labels.append(dataset['label'].loc[i])\n        img = img[:,:,dataset['slice'].loc[i]]\n        mask = mask[:,:,dataset['slice'].loc[i]]\n        mask = (mask>0).astype('float64')\n        img = img*mask\n        img = ExtractRegion(img)\n        img = img.reshape(3,240,240)\n        X.append(img)\n    X = torch.tensor(X)\n    labels = np.array(labels)\n    preds_vgg = model_vgg(X)\n    preds_resnet = model_resnet(X)\n    X = torch.cat((preds_vgg,preds_resnet),dim=1)\n    y_preds = model.predict(X)\n    print(classification_report(labels,y_preds))\n    \n\ndef fit(train_set):\n    model = tree.DecisionTreeClassifier()\n    labels = []\n    X=[]\n    for i in tqdm_notebook(range(int(len(train_set)))):\n        img = nib.load(f\"./brain_images/BraTS2021_{dataset['id'].loc[i]}/BraTS2021_{dataset['id'].loc[i]}_t1.nii.gz\").get_fdata()\n        mask = nib.load(f\"./brain_images/BraTS2021_{dataset['id'].loc[i]}/BraTS2021_{dataset['id'].loc[i]}_seg.nii.gz\").get_fdata()\n        labels.append(dataset['label'].loc[i])\n        img = img[:,:,dataset['slice'].loc[i]]\n        mask = mask[:,:,dataset['slice'].loc[i]]\n        mask = (mask>0).astype('float64')\n        img = img*mask\n        img = ExtractRegion(img)\n        img = img.reshape(3,240,240)\n        X.append(img)\n    X=torch.tensor(X)\n    labels = np.array(labels)\n    preds_vgg = model_vgg(X)\n    preds_resnet = model_resnet(X)\n    X = torch.cat((preds_vgg,preds_resnet),dim=1)\n    model.fit(X,labels)\n    print(labels)\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2022-04-04T06:32:58.209571Z","iopub.execute_input":"2022-04-04T06:32:58.209853Z","iopub.status.idle":"2022-04-04T06:32:58.226882Z","shell.execute_reply.started":"2022-04-04T06:32:58.209823Z","shell.execute_reply":"2022-04-04T06:32:58.226161Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"m=fit(dataset.loc[0:230])\npredict(dataset.loc[500:1000],m)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T06:40:47.466383Z","iopub.execute_input":"2022-04-04T06:40:47.466671Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/231 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"127a27b9831448c5803ee8ae604c224a"}},"metadata":{}},{"name":"stdout","text":"[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/501 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e677a67c61e54087898e5cf20e626c43"}},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2022-04-04T06:04:31.525568Z","iopub.execute_input":"2022-04-04T06:04:31.526357Z","iopub.status.idle":"2022-04-04T06:04:31.553801Z","shell.execute_reply.started":"2022-04-04T06:04:31.526308Z","shell.execute_reply":"2022-04-04T06:04:31.552886Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"          id  slice  label\n0      00000     51      1\n1      00000     52      1\n2      00000     53      1\n3      00000     54      1\n4      00000     55      1\n...      ...    ...    ...\n30971  01010     71      0\n30972  01010     72      0\n30973  01010     73      0\n30974  01010     74      0\n30975  01010     75      0\n\n[30976 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>slice</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000</td>\n      <td>51</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00000</td>\n      <td>52</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00000</td>\n      <td>53</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00000</td>\n      <td>54</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00000</td>\n      <td>55</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>30971</th>\n      <td>01010</td>\n      <td>71</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>30972</th>\n      <td>01010</td>\n      <td>72</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>30973</th>\n      <td>01010</td>\n      <td>73</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>30974</th>\n      <td>01010</td>\n      <td>74</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>30975</th>\n      <td>01010</td>\n      <td>75</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>30976 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"features = {}\nfor i in tqdm_notebook(range(len(dataset))):\n    img = nib.load(f\"./brain_images/BraTS2021_{dataset['id'].loc[i]}/BraTS2021_{dataset['id'].loc[i]}_t1.nii.gz\").get_fdata()\n    mask = nib.load(f\"./brain_images/BraTS2021_{dataset['id'].loc[i]}/BraTS2021_{dataset['id'].loc[i]}_seg.nii.gz\").get_fdata()\n    img = img[:,:,dataset['slice'].loc[i]]\n    mask = mask[:,:,dataset['slice'].loc[i]]\n    mask = (mask>0).astype('float64')\n    img = img*mask\n    img = ExtractRegion(img)\n    img = img.reshape(3,240,240)\n    img = torch.tensor([img])\n    preds_vgg = model_vgg(img)\n    preds_resnet = model_resnet(img)\n    preds_combined = torch.cat((preds_vgg,preds_resnet),dim=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T05:08:23.777932Z","iopub.execute_input":"2022-04-04T05:08:23.77849Z","iopub.status.idle":"2022-04-04T05:08:28.683791Z","shell.execute_reply.started":"2022-04-04T05:08:23.77844Z","shell.execute_reply":"2022-04-04T05:08:28.682257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-04-04T05:06:33.795923Z","iopub.execute_input":"2022-04-04T05:06:33.796572Z","iopub.status.idle":"2022-04-04T05:06:33.805614Z","shell.execute_reply.started":"2022-04-04T05:06:33.796531Z","shell.execute_reply":"2022-04-04T05:06:33.804624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision.models as models\nimport torch.nn as nn\nmodel_vgg=models.vgg16(pretrained=True)\nmodel_resnet=models.resnet18(pretrained=True)\nmodel_vgg.classifier = model_vgg.classifier[:2]\nmodel_resnet.fc = nn.Identity()\nfor param in model_vgg.parameters():\n    param.requires_grad = False\nfor param in model_resnet.parameters():\n    param.requires_grad = False\n# num_ftrs_resnet = model_resnet.fc.in_features\n# num_ftrs_vgg=model_vgg.classifier[0].in_features\n# model_resnet.fc=nn.Linear(num_ftrs_resnet,256)\n# model_vgg.classifier=nn.Linear(num_ftrs_vgg,256)\n# def computeFeautures(img):\n#     img = img.reshape((3,240,240))\n#     img = np.array([img])\n#     img = torch.tensor(img)\n#     vgg_out = model_vgg(img)\n#     resnet_out = model_resnet(img)\n#     comb_out=torch.cat((vgg_out,resnet_out),dim=1)\n#     return comb_out","metadata":{"execution":{"iopub.status.busy":"2022-04-04T06:11:26.851329Z","iopub.execute_input":"2022-04-04T06:11:26.85163Z","iopub.status.idle":"2022-04-04T06:11:33.695585Z","shell.execute_reply.started":"2022-04-04T06:11:26.851593Z","shell.execute_reply":"2022-04-04T06:11:33.694648Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/528M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a63ef2dd6f0e4265916f3164b4b80cf4"}},"metadata":{}},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/44.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a771e2fcbd694bcca5d3b2184c0bc60f"}},"metadata":{}}]},{"cell_type":"code","source":"model_vgg","metadata":{"execution":{"iopub.status.busy":"2022-04-04T05:06:45.070981Z","iopub.execute_input":"2022-04-04T05:06:45.071601Z","iopub.status.idle":"2022-04-04T05:06:45.079048Z","shell.execute_reply.started":"2022-04-04T05:06:45.071559Z","shell.execute_reply":"2022-04-04T05:06:45.077841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_features(name):\n    def hook(model, input, output):\n        features[name] = output.detach()\n    return hook\nmodel_vgg.AdaptiveAvgPool.register_forward_hook(get_features('feats'))","metadata":{"execution":{"iopub.status.busy":"2022-04-04T04:11:38.57248Z","iopub.execute_input":"2022-04-04T04:11:38.574093Z","iopub.status.idle":"2022-04-04T04:11:38.581001Z","shell.execute_reply.started":"2022-04-04T04:11:38.574026Z","shell.execute_reply":"2022-04-04T04:11:38.580329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2022-04-04T04:17:39.369317Z","iopub.execute_input":"2022-04-04T04:17:39.369683Z","iopub.status.idle":"2022-04-04T04:17:39.39995Z","shell.execute_reply.started":"2022-04-04T04:17:39.36965Z","shell.execute_reply":"2022-04-04T04:17:39.399282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-04-04T04:17:29.463555Z","iopub.execute_input":"2022-04-04T04:17:29.463885Z","iopub.status.idle":"2022-04-04T04:17:29.493364Z","shell.execute_reply.started":"2022-04-04T04:17:29.463851Z","shell.execute_reply":"2022-04-04T04:17:29.492205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nimport cv2\nclass MRI_Dataset(Dataset):\n    def __init__(self,dataset, annotations_file, transform=None):\n        self.dataset=dataset\n        self.img_labels = pd.read_csv(annotations_file)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, idx):\n        _id,_slice=self.dataset[idx]\n        img_path = f\"./brain_images/BraTS2021_{str(_id).zfill(5)}/BraTS2021_{_id}_t1.nii.gz\"\n        image = nib.load(img_path)\n        image = image.get_fdata()[:,:,_slice]\n        image = cv2.cvtColor(image.astype('float32'),cv2.COLOR_GRAY2RGB)\n        label = self.img_labels[self.img_labels['BraTS21ID']==int(_id)]['MGMT_value'].values[0]\n        if self.transform:\n            image = self.transform(image)\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2022-04-03T09:54:01.682721Z","iopub.execute_input":"2022-04-03T09:54:01.682998Z","iopub.status.idle":"2022-04-03T09:54:01.693619Z","shell.execute_reply.started":"2022-04-03T09:54:01.682969Z","shell.execute_reply":"2022-04-03T09:54:01.692926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_data=MRI_Dataset(ALL_DATA,'../input/mgmt-labels/train_labels_MGMT.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-03T09:54:01.69563Z","iopub.execute_input":"2022-04-03T09:54:01.695936Z","iopub.status.idle":"2022-04-03T09:54:01.715912Z","shell.execute_reply.started":"2022-04-03T09:54:01.695895Z","shell.execute_reply":"2022-04-03T09:54:01.715036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Normalise_range(object):\n    def __init__(self, min_t,max_t):\n        self.min_t = min_t\n        self.max_t = max_t\n\n    def __call__(self, sample):\n        image = sample\n        ## Minmax Normalisation to 0 to 255\n        image=image-self.min_t\n        image=image/(self.max_t-self.min_t)\n        return image\n","metadata":{"execution":{"iopub.status.busy":"2022-04-03T05:14:44.389686Z","iopub.status.idle":"2022-04-03T05:14:44.390213Z","shell.execute_reply.started":"2022-04-03T05:14:44.389963Z","shell.execute_reply":"2022-04-03T05:14:44.389994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader\nimport torchvision.models as models\ntrain,test = train_test_split(ALL_DATA, test_size=0.33, random_state=42)\ntraining_data=MRI_Dataset(train,'../input/mgmt-labels/train_labels_MGMT.csv',transform=transforms.Compose([\n                                               Normalise_range(MIN_T1,MAX_T1)  ,\n                                               transforms.ToTensor() ,\n                                               transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n                                           ]))\ntest_data=MRI_Dataset(test,'../input/mgmt-labels/train_labels_MGMT.csv')\ntrain_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\ntest_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-03T05:05:09.983178Z","iopub.execute_input":"2022-04-03T05:05:09.98381Z","iopub.status.idle":"2022-04-03T05:05:11.311009Z","shell.execute_reply.started":"2022-04-03T05:05:09.983773Z","shell.execute_reply":"2022-04-03T05:05:11.309796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_data[32]","metadata":{"execution":{"iopub.status.busy":"2022-04-03T05:10:59.987231Z","iopub.execute_input":"2022-04-03T05:10:59.987561Z","iopub.status.idle":"2022-04-03T05:11:00.088787Z","shell.execute_reply.started":"2022-04-03T05:10:59.987523Z","shell.execute_reply":"2022-04-03T05:11:00.088109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn","metadata":{"execution":{"iopub.status.busy":"2022-04-03T04:09:27.215847Z","iopub.execute_input":"2022-04-03T04:09:27.216624Z","iopub.status.idle":"2022-04-03T04:09:27.221158Z","shell.execute_reply.started":"2022-04-03T04:09:27.216584Z","shell.execute_reply":"2022-04-03T04:09:27.219948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out = model_resnet(i.float())","metadata":{"execution":{"iopub.status.busy":"2022-03-21T05:41:48.188524Z","iopub.execute_input":"2022-03-21T05:41:48.189411Z","iopub.status.idle":"2022-03-21T05:41:56.18969Z","shell.execute_reply.started":"2022-03-21T05:41:48.189368Z","shell.execute_reply":"2022-03-21T05:41:56.188647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class NeuralNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.vgg=torch.hub.load('pytorch/vision:v0.10.0', 'vgg19', pretrained=True).float()\n        self.resnet=torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True).float()\n        for param in self.vgg.parameters():\n            param.requires_grad = False\n        for param in self.resnet.parameters():\n            param.requires_grad = False\n        num_ftrs_resnet = self.resnet.fc.in_features\n        num_ftrs_vgg=self.vgg.classifier[0].in_features\n        self.resnet.fc=nn.Linear(num_ftrs_resnet,256)\n        self.vgg.classifier=nn.Linear(num_ftrs_vgg,256)\n        self.fc=nn.Sequential(\n            nn.Linear(512,256),\n            nn.ReLU(),\n            nn.Linear(256,128),\n            nn.ReLU(),\n            nn.Linear(128,64),\n            nn.ReLU(),\n            nn.Linear(64,1),\n            nn.Sigmoid()\n        )\n        \n    def forward(self, img):\n        vgg_out = self.vgg(img)\n        resnet_out = self.resnet(img)\n        comb_out=torch.cat((vgg_out,resnet_out),dim=1)\n        result=self.fc(comb_out)\n        print(vgg_out.shape)\n        print(resnet_out.shape)\n        print(comb_out.shape)\n        print(result.shape)\n        print(result)\n        ","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:29:19.126864Z","iopub.execute_input":"2022-03-21T09:29:19.127209Z","iopub.status.idle":"2022-03-21T09:29:19.141108Z","shell.execute_reply.started":"2022-03-21T09:29:19.127173Z","shell.execute_reply":"2022-03-21T09:29:19.139977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Model=NeuralNetwork()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:29:19.582715Z","iopub.execute_input":"2022-03-21T09:29:19.583241Z","iopub.status.idle":"2022-03-21T09:29:21.668183Z","shell.execute_reply.started":"2022-03-21T09:29:19.583202Z","shell.execute_reply":"2022-03-21T09:29:21.667261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i,j in train_dataloader:\n    Model(i.float())","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:29:21.66964Z","iopub.execute_input":"2022-03-21T09:29:21.669872Z","iopub.status.idle":"2022-03-21T09:30:55.960199Z","shell.execute_reply.started":"2022-03-21T09:29:21.669842Z","shell.execute_reply":"2022-03-21T09:30:55.958979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model_vgg_inftrs)\nprint(model_vgg)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:00:11.400093Z","iopub.execute_input":"2022-03-21T09:00:11.401021Z","iopub.status.idle":"2022-03-21T09:00:11.407164Z","shell.execute_reply.started":"2022-03-21T09:00:11.40097Z","shell.execute_reply":"2022-03-21T09:00:11.40612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model_resnet)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T08:59:40.625658Z","iopub.execute_input":"2022-03-21T08:59:40.62598Z","iopub.status.idle":"2022-03-21T08:59:40.63174Z","shell.execute_reply.started":"2022-03-21T08:59:40.625936Z","shell.execute_reply":"2022-03-21T08:59:40.630975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}