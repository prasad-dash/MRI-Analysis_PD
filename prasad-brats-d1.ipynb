{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import nibabel as nib\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport os\nimport random\nimport torch\nimport pandas as pd\nfrom tqdm.notebook import tqdm_notebook\n","metadata":{"execution":{"iopub.status.busy":"2022-03-21T08:02:31.327104Z","iopub.execute_input":"2022-03-21T08:02:31.327441Z","iopub.status.idle":"2022-03-21T08:02:32.730312Z","shell.execute_reply.started":"2022-03-21T08:02:31.327358Z","shell.execute_reply":"2022-03-21T08:02:32.729645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tarfile\nfile = tarfile.open('../input/brats-2021-task1/BraTS2021_Training_Data.tar')\n\nfile.extractall('./brain_images')\nfile.close()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T08:02:35.692284Z","iopub.execute_input":"2022-03-21T08:02:35.692594Z","iopub.status.idle":"2022-03-21T08:05:14.414815Z","shell.execute_reply.started":"2022-03-21T08:02:35.692548Z","shell.execute_reply":"2022-03-21T08:05:14.413917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATIENT_ID=input()\nT1_PATH=f\"./brain_images/BraTS2021_{PATIENT_ID}/BraTS2021_{PATIENT_ID}_t1.nii.gz\"\nT1CE_PATH=f\"./brain_images/BraTS2021_{PATIENT_ID}/BraTS2021_{PATIENT_ID}_t1ce.nii.gz\"\nT2_PATH=f\"./brain_images/BraTS2021_{PATIENT_ID}/BraTS2021_{PATIENT_ID}_t2.nii.gz\"\nFLAIR_PATH=f\"./brain_images/BraTS2021_{PATIENT_ID}/BraTS2021_{PATIENT_ID}_flair.nii.gz\"\nMASK_PATH=f\"./brain_images/BraTS2021_{PATIENT_ID}/BraTS2021_{PATIENT_ID}_seg.nii.gz\"\nimg_t1=nib.load(T1_PATH)\nimg_t1ce=nib.load(T1CE_PATH)\nimg_t2=nib.load(T2_PATH)\nimg_flair=nib.load(FLAIR_PATH)\nimg_mask=nib.load(MASK_PATH)\nimage_data_t1=img_t1.get_fdata()\nimage_data_t1ce=img_t1ce.get_fdata()\nimage_data_t2=img_t2.get_fdata()\nimage_data_flair=img_flair.get_fdata()\nmask=img_mask.get_fdata()\nprint(img_t1.header)\nzero_matrix=np.zeros((240,240))\nstart=-1\nend=1e9\nnonEmptyMasks=[]\nfor i in range(0,155):\n    if not np.array_equal(zero_matrix,mask[:,:,i]):\n        if start==-1:\n                start=i\n        nonEmptyMasks.append(i)\n        if i<end:\n            end=i\n\ndef one_normal(x):\n    if x==0:\n        return 0\n    else:\n        return 1\nplt.rcParams.update({'text.color': \"red\"})\nLAYER=random.choice(nonEmptyMasks)\nfig = plt.figure(figsize=(100,50))\nrows = 5\ncols=1\nfig.add_subplot(rows, cols, 1)\ncmask=np.vectorize(one_normal)(mask[:,:,LAYER])\nplt.imshow(image_data_t1[:,:,LAYER]*cmask,cmap='gray')\nplt.axis('off')\nplt.title(\"T1\")\nfig.add_subplot(rows, cols,2)\nplt.imshow(image_data_t1ce[:,:,LAYER]*cmask,cmap='gray')\nplt.axis('off')\nplt.title(\"T1CE\")\nfig.add_subplot(rows, cols, 3)\nplt.imshow(image_data_t2[:,:,LAYER]*cmask,cmap='gray')\nplt.axis('off')\nplt.title(\"T2\")\nfig.add_subplot(rows, cols, 4)\nplt.imshow(image_data_flair[:,:,LAYER]*cmask,cmap='gray')\nplt.axis('off')\nplt.title(\"FLAIR\")\nfig.add_subplot(rows, cols, 5)\nplt.imshow(mask[:,:,LAYER],cmap='gray')\nplt.axis('off')\nplt.title(\"MASK\")\nfig.suptitle(f'Layer Number {LAYER}', fontsize=20)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-21T05:03:44.095792Z","iopub.execute_input":"2022-03-21T05:03:44.096447Z","iopub.status.idle":"2022-03-21T05:03:52.913621Z","shell.execute_reply.started":"2022-03-21T05:03:44.096326Z","shell.execute_reply":"2022-03-21T05:03:52.912119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels=pd.read_csv('../input/mgmt-labels/train_labels_MGMT.csv')\nCURRENT_FOLDER='./brain_images'\nALL_PATIENTS=[]\nfor f in tqdm_notebook(os.listdir(CURRENT_FOLDER),desc='Progress'):\n    path_to_dir=os.path.join(CURRENT_FOLDER,f)\n    if os.path.isdir(path_to_dir):\n        ALL_PATIENTS.append(f)\nALL_MGMT_PATIENTS=[str(label).zfill(5) for label in labels['BraTS21ID']]\nprint(\"Total Number of patients : \",len(ALL_PATIENTS))\nprint(\"Total Number of patients with MGMT Data : \",len(ALL_MGMT_PATIENTS))\nprint(\"Total Number of patients with MGMT Methylation Positive : \",len(labels[labels['MGMT_value']==1]))\nprint(\"Total Number of patients with MGMT Methylation Negative : \",len(labels[labels['MGMT_value']==0]))","metadata":{"execution":{"iopub.status.busy":"2022-03-21T08:05:27.442087Z","iopub.execute_input":"2022-03-21T08:05:27.442383Z","iopub.status.idle":"2022-03-21T08:05:27.533975Z","shell.execute_reply.started":"2022-03-21T08:05:27.44235Z","shell.execute_reply":"2022-03-21T08:05:27.533243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in ALL_MGMT_PATIENTS:\n    if f'BraTS2021_{i}' not in ALL_PATIENTS:\n        print(i)\nALL_MGMT_PATIENTS=[i for i in ALL_MGMT_PATIENTS if f'BraTS2021_{i}' in ALL_PATIENTS]","metadata":{"execution":{"iopub.status.busy":"2022-03-21T08:05:31.341758Z","iopub.execute_input":"2022-03-21T08:05:31.34206Z","iopub.status.idle":"2022-03-21T08:05:31.368217Z","shell.execute_reply.started":"2022-03-21T08:05:31.342027Z","shell.execute_reply":"2022-03-21T08:05:31.366666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_T1=-1\nMIN_T1=1e9\nfor i in tqdm_notebook(ALL_MGMT_PATIENTS,desc='T1'):\n    img_t1=nib.load(f\"./brain_images/BraTS2021_{i}/BraTS2021_{i}_t1.nii.gz\")\n    image_data=img_t1.get_fdata()\n    MAX_T1=max(MAX_T1,image_data.max())\n    MIN_T1=min(MIN_T1,image_data.min())\nprint(\"Max Intensity in T1 Images : \",MAX_T1)\nprint(\"Min Intensity in T1 Images : \",MIN_T1)\nMAX_T1CE=-1\nMIN_T1CE=1e9\nfor i in tqdm_notebook(ALL_MGMT_PATIENTS,desc='T1CE'):\n    img_t1=nib.load(f\"./brain_images/BraTS2021_{i}/BraTS2021_{i}_t1ce.nii.gz\")\n    image_data=img_t1.get_fdata()\n    MAX_T1CE=max(MAX_T1CE,image_data.max())\n    MIN_T1CE=min(MIN_T1CE,image_data.min())\nprint(\"Max Intensity in T1 Images : \",MAX_T1CE)\nprint(\"Min Intensity in T1 Images : \",MIN_T1CE)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-21T08:05:46.991316Z","iopub.execute_input":"2022-03-21T08:05:46.99175Z","iopub.status.idle":"2022-03-21T08:08:07.967602Z","shell.execute_reply.started":"2022-03-21T08:05:46.991711Z","shell.execute_reply":"2022-03-21T08:08:07.966596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_T2=-1\nMIN_T2=1e9\nfor i in tqdm_notebook(ALL_MGMT_PATIENTS,desc='T2'):\n    img_t1=nib.load(f\"./brain_images/BraTS2021_{i}/BraTS2021_{i}_t2.nii.gz\")\n    image_data=img_t1.get_fdata()\n    MAX_T2=max(MAX_T2,image_data.max())\n    MIN_T2=min(MIN_T2,image_data.min())\nprint(\"Max Intensity in T2 Images : \",MAX_T2)\nprint(\"Min Intensity in T2 Images : \",MIN_T2)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_FLAIR=-1\nMIN_FLAIR=1e9\nfor i in tqdm_notebook(ALL_MGMT_PATIENTS,desc='FLAIR'):\n    img_t1=nib.load(f\"./brain_images/BraTS2021_{i}/BraTS2021_{i}_flair.nii.gz\")\n    image_data=img_t1.get_fdata()\n    MAX_FLAIR=max(MAX_FLAIR,image_data.max())\n    MIN_FLAIR=min(MIN_FLAIR,image_data.min())\nprint(\"Max Intensity in FLAIR Images : \",MAX_FLAIR)\nprint(\"Min Intensity in FLAIR Images : \",MIN_FLAIR)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ALL_DATA=[]\nfor i in tqdm_notebook(ALL_MGMT_PATIENTS,desc='Progress'):\n    zero_matrix=np.zeros((240,240))\n    start=-1\n    end=1e9\n    nonEmptyMasks=[]\n    MASK_PATH=f\"./brain_images/BraTS2021_{i}/BraTS2021_{i}_seg.nii.gz\"\n    img_mask=nib.load(MASK_PATH)\n    mask=img_mask.get_fdata()\n    for j in range(0,155):\n        if not np.array_equal(zero_matrix,mask[:,:,j]):\n            ALL_DATA.append((i,j))\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-21T08:08:07.969358Z","iopub.execute_input":"2022-03-21T08:08:07.969612Z","iopub.status.idle":"2022-03-21T08:08:57.607584Z","shell.execute_reply.started":"2022-03-21T08:08:07.969573Z","shell.execute_reply":"2022-03-21T08:08:57.606711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(ALL_DATA)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T19:51:43.790172Z","iopub.execute_input":"2022-03-20T19:51:43.790991Z","iopub.status.idle":"2022-03-20T19:51:43.796656Z","shell.execute_reply.started":"2022-03-20T19:51:43.790952Z","shell.execute_reply":"2022-03-20T19:51:43.796082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nclass MRI_Dataset(Dataset):\n    def __init__(self,dataset, annotations_file, transform=None):\n        self.dataset=dataset\n        self.img_labels = pd.read_csv(annotations_file)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, idx):\n        _id,_slice=self.dataset[idx]\n        img_path = f\"./brain_images/BraTS2021_{str(_id).zfill(5)}/BraTS2021_{str(_id).zfill(5)}_t1.nii.gz\"\n        image = nib.load(img_path)\n        image=image.get_fdata()[:,:,_slice]\n        image = np.tile(image,(3,1,1))\n        image=image.reshape(240,240,3)\n        label = self.img_labels[self.img_labels['BraTS21ID']==int(_id)]['MGMT_value'].values[0]\n        if self.transform:\n            image = self.transform(image)\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2022-03-21T08:11:27.648393Z","iopub.execute_input":"2022-03-21T08:11:27.648653Z","iopub.status.idle":"2022-03-21T08:11:27.658226Z","shell.execute_reply.started":"2022-03-21T08:11:27.648624Z","shell.execute_reply":"2022-03-21T08:11:27.657111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision import transforms, utils\nclass Normalise_range(object):\n    \"\"\"Rescale the image in a sample to a given size.\n\n    Args:\n        output_size (tuple or int): Desired output size. If tuple, output is\n            matched to output_size. If int, smaller of image edges is matched\n            to output_size keeping aspect ratio the same.\n    \"\"\"\n\n    def __init__(self, min_t,max_t):\n\n        self.min_t = min_t\n        self.max_t = max_t\n\n    def __call__(self, sample):\n        image = sample\n        ## Minmax Normalisation to 0 to 255\n        image=image-self.min_t\n        image=image/(self.max_t-self.min_t)\n        return image\n","metadata":{"execution":{"iopub.status.busy":"2022-03-21T08:12:54.430879Z","iopub.execute_input":"2022-03-21T08:12:54.431363Z","iopub.status.idle":"2022-03-21T08:12:54.437266Z","shell.execute_reply.started":"2022-03-21T08:12:54.431328Z","shell.execute_reply":"2022-03-21T08:12:54.436358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader\nimport torchvision.models as models\ntrain,test = train_test_split(ALL_DATA, test_size=0.33, random_state=42)\ntraining_data=MRI_Dataset(train,'../input/mgmt-labels/train_labels_MGMT.csv',transform=transforms.Compose([\n                                               Normalise_range(MIN_T1,MAX_T1)  ,\n                                               transforms.ToTensor() ,\n                                               transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n                                           ]))\ntest_data=MRI_Dataset(test,'../input/mgmt-labels/train_labels_MGMT.csv')\ntrain_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\ntest_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:05:44.419971Z","iopub.execute_input":"2022-03-21T09:05:44.420279Z","iopub.status.idle":"2022-03-21T09:05:44.467949Z","shell.execute_reply.started":"2022-03-21T09:05:44.420248Z","shell.execute_reply":"2022-03-21T09:05:44.466906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:04:08.039911Z","iopub.execute_input":"2022-03-21T09:04:08.040169Z","iopub.status.idle":"2022-03-21T09:04:08.044258Z","shell.execute_reply.started":"2022-03-21T09:04:08.040142Z","shell.execute_reply":"2022-03-21T09:04:08.043412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out = model_resnet(i.float())","metadata":{"execution":{"iopub.status.busy":"2022-03-21T05:41:48.188524Z","iopub.execute_input":"2022-03-21T05:41:48.189411Z","iopub.status.idle":"2022-03-21T05:41:56.18969Z","shell.execute_reply.started":"2022-03-21T05:41:48.189368Z","shell.execute_reply":"2022-03-21T05:41:56.188647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class NeuralNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.vgg=torch.hub.load('pytorch/vision:v0.10.0', 'vgg19', pretrained=True).float()\n        self.resnet=torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True).float()\n        for param in self.vgg.parameters():\n            param.requires_grad = False\n        for param in self.resnet.parameters():\n            param.requires_grad = False\n        num_ftrs_resnet = self.resnet.fc.in_features\n        num_ftrs_vgg=self.vgg.classifier[0].in_features\n        self.resnet.fc=nn.Linear(num_ftrs_resnet,256)\n        self.vgg.classifier=nn.Linear(num_ftrs_vgg,256)\n        self.fc=nn.Sequential(\n            nn.Linear(512,256),\n            nn.ReLU(),\n            nn.Linear(256,128),\n            nn.ReLU(),\n            nn.Linear(128,64),\n            nn.ReLU(),\n            nn.Linear(64,1),\n            nn.Sigmoid()\n        )\n        \n    def forward(self, img):\n        vgg_out = self.vgg(img)\n        resnet_out = self.resnet(img)\n        comb_out=torch.cat((vgg_out,resnet_out),dim=1)\n        result=self.fc(comb_out)\n        print(vgg_out.shape)\n        print(resnet_out.shape)\n        print(comb_out.shape)\n        print(result.shape)\n        print(result)\n        ","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:29:19.126864Z","iopub.execute_input":"2022-03-21T09:29:19.127209Z","iopub.status.idle":"2022-03-21T09:29:19.141108Z","shell.execute_reply.started":"2022-03-21T09:29:19.127173Z","shell.execute_reply":"2022-03-21T09:29:19.139977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Model=NeuralNetwork()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:29:19.582715Z","iopub.execute_input":"2022-03-21T09:29:19.583241Z","iopub.status.idle":"2022-03-21T09:29:21.668183Z","shell.execute_reply.started":"2022-03-21T09:29:19.583202Z","shell.execute_reply":"2022-03-21T09:29:21.667261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i,j in train_dataloader:\n    Model(i.float())","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:29:21.66964Z","iopub.execute_input":"2022-03-21T09:29:21.669872Z","iopub.status.idle":"2022-03-21T09:30:55.960199Z","shell.execute_reply.started":"2022-03-21T09:29:21.669842Z","shell.execute_reply":"2022-03-21T09:30:55.958979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model_vgg_inftrs)\nprint(model_vgg)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:00:11.400093Z","iopub.execute_input":"2022-03-21T09:00:11.401021Z","iopub.status.idle":"2022-03-21T09:00:11.407164Z","shell.execute_reply.started":"2022-03-21T09:00:11.40097Z","shell.execute_reply":"2022-03-21T09:00:11.40612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model_resnet)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T08:59:40.625658Z","iopub.execute_input":"2022-03-21T08:59:40.62598Z","iopub.status.idle":"2022-03-21T08:59:40.63174Z","shell.execute_reply.started":"2022-03-21T08:59:40.625936Z","shell.execute_reply":"2022-03-21T08:59:40.630975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}